import gradio as gr
import edge_tts
import asyncio
import os
import re
from moviepy.editor import *
import numpy as np
from PIL import Image

# ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞ MultilingualNeural
async def get_supported_voices():
    voices = await edge_tts.list_voices()
    supported = {}
    
    for voice in voices:
        short_name = voice['ShortName']
        gender = voice['Gender']
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞ MultilingualNeural
        if 'th-TH' in short_name or 'MultilingualNeural' in short_name:
            # ‡πÉ‡∏ä‡πâ ShortName ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏û‡∏®
            clean_name = f"{short_name} ({'F' if gender == 'Female' else 'M'})"
            supported[clean_name] = short_name
    
    return supported

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏¥‡∏ó‡∏≤‡∏ô
EXAMPLE_STORIES = {
    "‡∏Å‡∏ö‡∏Å‡∏±‡∏ö‡∏ô‡∏Å‡∏¢‡∏π‡∏á": """[speaker1] ‡∏Å‡∏≤‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ô‡∏≤‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏µ‡∏Å‡∏ö‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ö‡∏∂‡∏á‡πÄ‡∏•‡πá‡∏Å‡πÜ
[speaker2] ‡∏ß‡∏±‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ô‡∏Å‡∏¢‡∏π‡∏á‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°‡∏ö‡∏¥‡∏ô‡∏°‡∏≤‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏£‡∏¥‡∏°‡∏ö‡∏∂‡∏á
[speaker1] ‡∏Å‡∏ö‡∏°‡∏≠‡∏á‡∏î‡∏π‡∏ô‡∏Å‡∏¢‡∏π‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¥‡∏à‡∏â‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ ‡∏Ç‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡∏ô‡∏™‡∏ß‡∏¢‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏à‡πâ‡∏≤
[speaker2] ‡∏ô‡∏Å‡∏¢‡∏π‡∏á‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ ‡πÅ‡∏ï‡πà‡πÄ‡∏à‡πâ‡∏≤‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡πÉ‡∏ô‡∏ô‡πâ‡∏≥‡πÑ‡∏î‡πâ ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
[speaker1] ‡∏Å‡∏ö‡∏à‡∏∂‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤ ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô""",
    
    "‡πÄ‡∏ï‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢": """[speaker1] ‡πÄ‡∏ï‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÅ‡∏Ç‡πà‡∏á‡∏ß‡∏¥‡πà‡∏á‡∏Å‡∏±‡∏ô
[speaker2] ‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤ ‡∏Ç‡πâ‡∏≤‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏ï‡πà‡∏≤‡∏°‡∏≤‡∏Å ‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å‡∏™‡∏±‡∏Å‡∏´‡∏ô‡πà‡∏≠‡∏¢
[speaker1] ‡πÄ‡∏ï‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏ô‡∏ä‡πâ‡∏≤‡πÜ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏±‡∏Å ‡πÄ‡∏î‡∏¥‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ
[speaker2] ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢‡∏ï‡∏∑‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ ‡πÄ‡∏ï‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏ß‡∏¥‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ä‡∏±‡∏¢‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
[speaker1] ‡πÄ‡∏ï‡πà‡∏≤‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ ‡∏ä‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏ï‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ó""",
    
    "‡∏°‡∏î‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡πä‡∏Å‡πÅ‡∏ï‡∏ô": """[speaker1] ‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô‡∏°‡∏î‡∏Ç‡∏¢‡∏±‡∏ô‡πÄ‡∏Å‡πá‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏ß‡πâ
[speaker2] ‡∏ï‡∏±‡πä‡∏Å‡πÅ‡∏ï‡∏ô‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞ ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏≤‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≤‡πÄ‡∏ñ‡∏≠‡∏∞
[speaker1] ‡∏°‡∏î‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ ‡∏Ç‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏§‡∏î‡∏π‡∏´‡∏ô‡∏≤‡∏ß
[speaker2] ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏§‡∏î‡∏π‡∏´‡∏ô‡∏≤‡∏ß‡∏°‡∏≤‡∏ñ‡∏∂‡∏á ‡∏ï‡∏±‡πä‡∏Å‡πÅ‡∏ï‡∏ô‡∏´‡∏¥‡∏ß‡πÇ‡∏´‡∏¢ ‡∏à‡∏∂‡∏á‡∏°‡∏≤‡∏Ç‡∏≠‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏°‡∏î
[speaker1] ‡∏°‡∏î‡πÉ‡∏´‡πâ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç""",
    
    "‡∏™‡∏∏‡∏ô‡∏±‡∏Ç‡∏Å‡∏±‡∏ö‡πÅ‡∏°‡∏ß": """[speaker1] ‡∏™‡∏∏‡∏ô‡∏±‡∏Ç‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏Å‡∏Å‡∏±‡∏ô
[speaker2] ‡∏ß‡∏±‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÅ‡∏°‡∏ß‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ ‡πÄ‡∏£‡∏≤‡πÑ‡∏õ‡∏´‡∏≤‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞
[speaker1] ‡∏™‡∏∏‡∏ô‡∏±‡∏Ç‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ ‡∏î‡∏µ‡∏ô‡∏∞ ‡∏Ç‡πâ‡∏≤‡∏´‡∏¥‡∏ß‡πÅ‡∏•‡πâ‡∏ß
[speaker2] ‡∏û‡∏ß‡∏Å‡πÄ‡∏Ç‡∏≤‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡∏´‡∏≤‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ó‡πà‡∏≤‡πÜ ‡∏Å‡∏±‡∏ô
[speaker1] ‡∏™‡∏∏‡∏ô‡∏±‡∏Ç‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ ‡∏°‡∏¥‡∏ï‡∏£‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Å‡∏±‡∏ô"""
}

def load_example_story(story_name):
    return EXAMPLE_STORIES[story_name]

# ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏° speaker tags
def parse_multispeaker_text(text):
    pattern = r'\[([^\]]+)\]\s*([^\[]*?)(?=\[|$)'
    matches = re.findall(pattern, text, re.DOTALL)
    return [(speaker.strip(), content.strip()) for speaker, content in matches if content.strip()]

# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° multi-speaker ‡πÅ‡∏ö‡∏ö‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå
async def textToSpeechMultiSeparate(text, speaker_data, supported_voices):
    if not text.strip():
        raise gr.Error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
    
    speaker_segments = parse_multispeaker_text(text)
    
    if not speaker_segments:
        raise gr.Error("‡πÑ‡∏°‡πà‡∏û‡∏ö speaker tags ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö [speaker1] ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° [speaker2] ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ speaker ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    required_speakers = set(speaker for speaker, _ in speaker_segments)
    available_speakers = set(speaker_data.keys())
    missing_speakers = required_speakers - available_speakers
    
    if missing_speakers:
        missing_list = ", ".join(sorted(missing_speakers))
        raise gr.Error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {missing_list} ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏° speaker ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ speaker ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
    for speaker in required_speakers:
        if not speaker_data[speaker].get('voice'):
            raise gr.Error(f"{speaker} ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô")
    
    try:
        all_audio_data = []
        
        for i, (speaker, content) in enumerate(speaker_segments):
            settings = speaker_data[speaker]
            voice_id = supported_voices[settings['voice']]
            
            rate_str = f"+{settings['rate']}%" if settings['rate'] >= 0 else f"{settings['rate']}%"
            volume_str = f"+{settings['volume']}%" if settings['volume'] >= 0 else f"{settings['volume']}%"
            
            communicate = edge_tts.Communicate(
                text=content,
                voice=voice_id,
                rate=rate_str,
                volume=volume_str
            )
            
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            
            all_audio_data.append(audio_data)
        
        combined_audio = b"".join(all_audio_data)
        
        output_file = os.path.join(os.path.dirname(__file__), "output_multispeaker.mp3")
        with open(output_file, "wb") as f:
            f.write(combined_audio)
        
        return output_file
        
    except Exception as e:
        raise gr.Error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")

def clearSpeech():
    output_file = os.path.join(os.path.dirname(__file__), "output_multispeaker.mp3")
    if os.path.exists(output_file):
        try:
            os.remove(output_file)
        except Exception:
            pass
    return None, None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢)
async def create_video_with_images(text, speaker_data, speaker_images, supported_voices):
    if not text.strip():
        raise gr.Error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    audio_file = os.path.join(os.path.dirname(__file__), "output_multispeaker.mp3")
    if not os.path.exists(audio_file):
        raise gr.Error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏î '‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á Multi-Speaker' ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠")
    
    speaker_segments = parse_multispeaker_text(text)
    
    try:
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        video_width, video_height = 1280, 720  # HD 720p
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ
        video_clips = []
        
        for i, (speaker, content) in enumerate(speaker_segments):
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥ (‡∏Ñ‡∏≥‡∏•‡∏∞ 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
            word_count = len(content.split())
            duration = max(word_count * 0.5, 2.0)  # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
            
            # ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á speaker
            speaker_image = speaker_images.get(speaker)
            
            if speaker_image:
                # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
                resized_image = speaker_image.resize((video_width, video_height), Image.Resampling.LANCZOS)
                
                # ‡πÅ‡∏õ‡∏•‡∏á PIL ‡πÄ‡∏õ‡πá‡∏ô numpy array
                img_array = np.array(resized_image)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á ImageClip
                img_clip = ImageClip(img_array, duration=duration)
                video_clips.append(img_clip)
            else:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ ‡πÉ‡∏ä‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏î‡∏≥
                color_clip = ColorClip(size=(video_width, video_height), color=(0, 0, 0), duration=duration)
                video_clips.append(color_clip)
        
        # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        final_video = concatenate_videoclips(video_clips, method="compose")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        audio_clip = AudioFileClip(audio_file)
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        if final_video.duration > audio_clip.duration:
            final_video = final_video.subclip(0, audio_clip.duration)
        elif final_video.duration < audio_clip.duration:
            # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏´‡πâ‡∏¢‡∏≤‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            last_clip = video_clips[-1]
            extended_clip = last_clip.set_duration(audio_clip.duration - (final_video.duration - last_clip.duration))
            video_clips[-1] = extended_clip
            final_video = concatenate_videoclips(video_clips, method="compose")
        
        final_video = final_video.set_audio(audio_clip)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        output_video = os.path.join(os.path.dirname(__file__), "output_video.mp4")
        final_video.write_videofile(output_video, fps=24, verbose=False, logger=None)
        
        return output_video
        
    except Exception as e:
        raise gr.Error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠: {str(e)}")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á UI
async def create_interface():
    # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    supported_voices = await get_supported_voices()
    voice_choices = list(supported_voices.keys())
    
    print(f"‡∏û‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö {len(supported_voices)} ‡πÄ‡∏™‡∏µ‡∏¢‡∏á:")
    for name in voice_choices:
        print(f"- {name}")
    
    with gr.Blocks(css="""
        .wrap-inner.svelte-1hfxrpf {
            font-size: 12px !important;
            line-height: 1.2 !important;
        }
        .dropdown select {
            font-size: 12px !important;
        }
        """, title="Dynamic Multi-Speaker TTS") as demo:
        
        gr.Markdown(f"""
        # Dynamic Multi-Speaker Text-to-Speech
        ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏•‡∏≤‡∏¢ speaker ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡∏û‡∏ö {len(supported_voices)} ‡πÄ‡∏™‡∏µ‡∏¢‡∏á)
        
        **‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:** ‡πÉ‡∏ä‡πâ [speaker1] ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° [speaker2] ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô:
        ```
        [speaker1] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
        [speaker2] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞
        [speaker1] ‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á
        ```
        """)
        
        with gr.Row():
            with gr.Column():
                text = gr.TextArea(
                    label="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° Multi-Speaker", 
                    placeholder="[speaker1] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö\n[speaker2] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞\n[speaker1] ‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á",
                    value="[speaker1] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö\n[speaker2] ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞\n[speaker1] ‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á",
                    lines=8
                )
                
                gr.Markdown("### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏¥‡∏ó‡∏≤‡∏ô")
                with gr.Row():
                    story1_btn = gr.Button("‡∏Å‡∏ö‡∏Å‡∏±‡∏ö‡∏ô‡∏Å‡∏¢‡∏π‡∏á", size="sm")
                    story2_btn = gr.Button("‡πÄ‡∏ï‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢", size="sm")
                with gr.Row():
                    story3_btn = gr.Button("‡∏°‡∏î‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡πä‡∏Å‡πÅ‡∏ï‡∏ô", size="sm")
                    story4_btn = gr.Button("‡∏™‡∏∏‡∏ô‡∏±‡∏Ç‡∏Å‡∏±‡∏ö‡πÅ‡∏°‡∏ß", size="sm")
                
                btn = gr.Button("‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á Multi-Speaker", variant="primary")
                video_btn = gr.Button("‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (‡πÄ‡∏™‡∏µ‡∏¢‡∏á + ‡∏£‡∏π‡∏õ)", variant="secondary")
                
            with gr.Column():
                gr.Markdown("### ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Speaker (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 speakers)")
                gr.Markdown("**üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏ô‡∏≤‡∏î 1280x720 ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô 16:9 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î")
                
                # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Speaker 1 ‡πÅ‡∏•‡∏∞ 2
                with gr.Group():
                    gr.Markdown("**Speaker 1**")
                    speaker1_voice = gr.Dropdown(
                        choices=voice_choices,
                        value=voice_choices[1] if len(voice_choices) > 1 else voice_choices[0],
                        label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á",
                        interactive=True
                    )
                    speaker1_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 1", type="pil", height=100)
                    with gr.Row():
                        speaker1_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker1_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                with gr.Group():
                    gr.Markdown("**Speaker 2**")
                    speaker2_voice = gr.Dropdown(
                        choices=voice_choices,
                        value=voice_choices[0],
                        label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á",
                        interactive=True
                    )
                    speaker2_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 2", type="pil", height=100)
                    with gr.Row():
                        speaker2_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker2_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                # Dynamic speakers container
                dynamic_speakers = gr.Column()
                
                # Hidden speakers (‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°)
                speaker3_group = gr.Group(visible=False)
                with speaker3_group:
                    gr.Markdown("**Speaker 3**")
                    speaker3_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker3_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 3", type="pil", height=100)
                    with gr.Row():
                        speaker3_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker3_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                speaker4_group = gr.Group(visible=False)
                with speaker4_group:
                    gr.Markdown("**Speaker 4**")
                    speaker4_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker4_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 4", type="pil", height=100)
                    with gr.Row():
                        speaker4_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker4_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                speaker5_group = gr.Group(visible=False)
                with speaker5_group:
                    gr.Markdown("**Speaker 5**")
                    speaker5_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker5_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 5", type="pil", height=100)
                    with gr.Row():
                        speaker5_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker5_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                speaker6_group = gr.Group(visible=False)
                with speaker6_group:
                    gr.Markdown("**Speaker 6**")
                    speaker6_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker6_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 6", type="pil", height=100)
                    with gr.Row():
                        speaker6_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker6_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                speaker7_group = gr.Group(visible=False)
                with speaker7_group:
                    gr.Markdown("**Speaker 7**")
                    speaker7_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker7_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 7", type="pil", height=100)
                    with gr.Row():
                        speaker7_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker7_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                speaker8_group = gr.Group(visible=False)
                with speaker8_group:
                    gr.Markdown("**Speaker 8**")
                    speaker8_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker8_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 8", type="pil", height=100)
                    with gr.Row():
                        speaker8_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker8_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                speaker9_group = gr.Group(visible=False)
                with speaker9_group:
                    gr.Markdown("**Speaker 9**")
                    speaker9_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker9_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 9", type="pil", height=100)
                    with gr.Row():
                        speaker9_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker9_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                speaker10_group = gr.Group(visible=False)
                with speaker10_group:
                    gr.Markdown("**Speaker 10**")
                    speaker10_voice = gr.Dropdown(choices=voice_choices, value=voice_choices[0], label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á", interactive=True)
                    speaker10_image = gr.Image(label="‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Speaker 10", type="pil", height=100)
                    with gr.Row():
                        speaker10_rate = gr.Slider(-100, 100, step=1, value=0, label="‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß")
                        speaker10_volume = gr.Slider(-100, 100, step=1, value=0, label="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                
                with gr.Row():
                    add_speaker_btn = gr.Button("+ ‡πÄ‡∏û‡∏¥‡πà‡∏° Speaker", variant="secondary")
                    remove_speaker_btn = gr.Button("- ‡∏•‡∏ö Speaker", variant="secondary")
                
                audio = gr.Audio(label="‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á", interactive=False)
                video_output = gr.Video(label="‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á", interactive=False)
                clear = gr.Button("‡∏•‡πâ‡∏≤‡∏á")
        
        # State ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• speaker
        speaker_count = gr.State(2)
        speaker_data_state = gr.State({
            "speaker1": {"voice": voice_choices[1] if len(voice_choices) > 1 else voice_choices[0], "rate": 0, "volume": 0},
            "speaker2": {"voice": voice_choices[0], "rate": 0, "volume": 0}
        })
        supported_voices_state = gr.State(supported_voices)
        
        # State ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        speaker_images_state = gr.State({})
        
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        def update_speaker_images(img1, img2, img3, img4, img5, img6, img7, img8, img9, img10):
            return {
                "speaker1": img1, "speaker2": img2, "speaker3": img3, "speaker4": img4, "speaker5": img5,
                "speaker6": img6, "speaker7": img7, "speaker8": img8, "speaker9": img9, "speaker10": img10
            }
        
        # Event handlers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        all_images = [speaker1_image, speaker2_image, speaker3_image, speaker4_image, speaker5_image,
                     speaker6_image, speaker7_image, speaker8_image, speaker9_image, speaker10_image]
        
        for img in all_images:
            img.change(
                fn=update_speaker_images,
                inputs=all_images,
                outputs=[speaker_images_state]
            )
        
        video_btn.click(
            fn=create_video_with_images,
            inputs=[text, speaker_data_state, speaker_images_state, supported_voices_state],
            outputs=[video_output]
        )
        
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• speaker
        def update_speaker_data(s1_voice, s1_rate, s1_vol, s2_voice, s2_rate, s2_vol):
            return {
                "speaker1": {"voice": s1_voice, "rate": s1_rate, "volume": s1_vol},
                "speaker2": {"voice": s2_voice, "rate": s2_rate, "volume": s2_vol}
            }
        
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• speaker ‡πÅ‡∏ö‡∏ö dynamic (10 speakers)
        def update_all_speakers(*args):
            count = args[-1]  # ‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏∑‡∏≠ count
            voices_rates_volumes = args[:-1]  # ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏∑‡∏≠ voice, rate, volume
            
            data = {}
            for i in range(min(count, 10)):
                speaker_key = f"speaker{i+1}"
                idx = i * 3
                data[speaker_key] = {
                    "voice": voices_rates_volumes[idx],
                    "rate": voices_rates_volumes[idx + 1], 
                    "volume": voices_rates_volumes[idx + 2]
                }
            return data
        
        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ speaker groups
        speaker_groups = [None, None, speaker3_group, speaker4_group, speaker5_group, 
                         speaker6_group, speaker7_group, speaker8_group, speaker9_group, speaker10_group]
        
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏° speaker
        def add_speaker_real(current_count):
            if current_count < 10:
                new_count = current_count + 1
                updates = []
                for i in range(2, 10):  # speaker3 ‡∏ñ‡∏∂‡∏á speaker10
                    if i == new_count - 1:
                        updates.append(gr.update(visible=True))
                    else:
                        updates.append(gr.update())
                return [new_count] + updates
            else:
                return [current_count] + [gr.update() for _ in range(8)]
        
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡∏ö speaker  
        def remove_speaker_real(current_count):
            if current_count > 2:
                new_count = current_count - 1
                updates = []
                for i in range(2, 10):  # speaker3 ‡∏ñ‡∏∂‡∏á speaker10
                    if i == current_count - 1:
                        updates.append(gr.update(visible=False))
                    else:
                        updates.append(gr.update())
                return [new_count] + updates
            else:
                return [current_count] + [gr.update() for _ in range(8)]
        
        # Event handlers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö speaker controls (‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß)
        all_controls = [
            speaker1_voice, speaker1_rate, speaker1_volume, 
            speaker2_voice, speaker2_rate, speaker2_volume,
            speaker3_voice, speaker3_rate, speaker3_volume, 
            speaker4_voice, speaker4_rate, speaker4_volume,
            speaker5_voice, speaker5_rate, speaker5_volume, 
            speaker6_voice, speaker6_rate, speaker6_volume,
            speaker7_voice, speaker7_rate, speaker7_volume, 
            speaker8_voice, speaker8_rate, speaker8_volume,
            speaker9_voice, speaker9_rate, speaker9_volume, 
            speaker10_voice, speaker10_rate, speaker10_volume
        ]
        
        for control in all_controls:
            control.change(
                fn=update_all_speakers,
                inputs=all_controls + [speaker_count],
                outputs=[speaker_data_state]
            )
        
        # Event handlers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏ö
        add_speaker_btn.click(
            fn=add_speaker_real,
            inputs=[speaker_count],
            outputs=[speaker_count] + [speaker3_group, speaker4_group, speaker5_group, 
                    speaker6_group, speaker7_group, speaker8_group, speaker9_group, speaker10_group]
        )
        
        remove_speaker_btn.click(
            fn=remove_speaker_real,
            inputs=[speaker_count],
            outputs=[speaker_count] + [speaker3_group, speaker4_group, speaker5_group, 
                    speaker6_group, speaker7_group, speaker8_group, speaker9_group, speaker10_group]
        )
        
        btn.click(
            fn=textToSpeechMultiSeparate,
            inputs=[text, speaker_data_state, supported_voices_state],
            outputs=[audio]
        )
        
        clear.click(
            fn=clearSpeech,
            outputs=[text, audio]
        )
        
        # Event handlers for story buttons
        story1_btn.click(fn=lambda: load_example_story("‡∏Å‡∏ö‡∏Å‡∏±‡∏ö‡∏ô‡∏Å‡∏¢‡∏π‡∏á"), outputs=[text])
        story2_btn.click(fn=lambda: load_example_story("‡πÄ‡∏ï‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢"), outputs=[text])
        story3_btn.click(fn=lambda: load_example_story("‡∏°‡∏î‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡πä‡∏Å‡πÅ‡∏ï‡∏ô"), outputs=[text])
        story4_btn.click(fn=lambda: load_example_story("‡∏™‡∏∏‡∏ô‡∏±‡∏Ç‡∏Å‡∏±‡∏ö‡πÅ‡∏°‡∏ß"), outputs=[text])
    
    return demo

if __name__ == "__main__":
    demo = asyncio.run(create_interface())
    demo.launch()
